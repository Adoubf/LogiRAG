import streamlit as st
from data.vector_store import load_faiss_store
from rag.chain import create_retrieval_chain


def setup_ui():
    """è®¾ç½®Streamlitç•Œé¢"""
    st.set_page_config(page_title="ç‰©æµè¡Œä¸šä¿¡æ¯å’¨è¯¢ç³»ç»Ÿ", layout="wide")
    st.title("ğŸšš ç‰©æµè¡Œä¸šä¿¡æ¯å’¨è¯¢ç³»ç»Ÿ")


def run_app():
    """è¿è¡ŒStreamlitåº”ç”¨"""
    setup_ui()

    # åŠ è½½å‘é‡åº“
    db = load_faiss_store()
    # å…¨å±€ä¸Šä¸‹æ–‡å†å²
    chat_history = []

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if prompt_text := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜:"):
        st.session_state.messages.append({"role": "user", "content": prompt_text})
        with st.chat_message("user"):
            st.markdown(prompt_text)

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""

            # æ˜¾å¼éªŒè¯å‘é‡åº“æ˜¯å¦å‘½ä¸­
            matched_docs = db.similarity_search(prompt_text, k=2)
            print("[DEBUG] ç›¸ä¼¼æ–‡æ¡£åŒ¹é…ç»“æœï¼š")
            for i, doc in enumerate(matched_docs):
                print(f"Doc {i + 1}: {doc.page_content}")

            chain = create_retrieval_chain(db.as_retriever())
            result = chain.invoke({"question": prompt_text, "chat_history": chat_history})

            answer = result["answer"]
            chat_history.append((prompt_text, answer))

            for chunk in answer.split():
                full_response += chunk + " "
                message_placeholder.markdown(full_response + "â–Œ")
            message_placeholder.markdown(full_response)

            print("[DEBUG] æ¨¡å‹å›ç­”ï¼š", answer)
            st.session_state.messages.append({"role": "assistant", "content": full_response})
